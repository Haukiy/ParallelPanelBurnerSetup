{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pylab\n",
    "import string\n",
    "import fdsreader\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import spotpy\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "from pyDOE import lhs\n",
    "import random\n",
    "import shutil\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LatinHypercube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latin Hypercube Sampling (LHS) is a statistical method used for generating a representative sample of parameter values from a multi-dimensional parameter space. The method involves dividing each dimension of the parameter space into equally-sized intervals and selecting one random point from each interval, such that each point is chosen exactly once. The resulting sample is thus representative of the parameter space in a more even and efficient way than a completely random sampling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the LHS sample using `LatinHypercube` from `scipy.stats.qmc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "\n",
    "# Define the number of dimensions and the number of samples to generate\n",
    "n_dims = 2\n",
    "n_samples = 10\n",
    "\n",
    "# Define the parameter ranges for each dimension\n",
    "params_ranges = np.array([[0, 1], [0, 1]])\n",
    "\n",
    "# Generate a Latin Hypercube sample within the parameter ranges\n",
    "sample = LatinHypercube(d=n_dims, seed=123).random(n_samples) * (params_ranges[:, 1] - params_ranges[:, 0]) + params_ranges[:, 0]\n",
    "\n",
    "# Create a grid to show the parameter space\n",
    "xx, yy = np.meshgrid(np.linspace(params_ranges[0, 0], params_ranges[0, 1], 10),\n",
    "                     np.linspace(params_ranges[1, 0], params_ranges[1, 1], 10))\n",
    "grid = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Plot the resulting sample and the parameter space grid\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axs[0].scatter(sample[:, 0], sample[:, 1])\n",
    "axs[0].set_xlabel('Parameter 1')\n",
    "axs[0].set_ylabel('Parameter 2')\n",
    "axs[0].set_title('Latin Hypercube Sample')\n",
    "\n",
    "axs[1].scatter(grid[:, 0], grid[:, 1], color='gray')\n",
    "axs[1].scatter(sample[:, 0], sample[:, 1])\n",
    "axs[1].set_xlabel('Parameter 1')\n",
    "axs[1].set_ylabel('Parameter 2')\n",
    "axs[1].set_title('Parameter Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latin Hypercube Sampling is designed to spread the sample points evenly throughout the parameter space, while still maintaining randomness. In other words, the LHS algorithm aims to fill the parameter space with points in such a way that each point is representative of a different region of the space, while avoiding clusters or gaps of points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameter settings:\n",
    "\n",
    "* PATH_LENGTH - constant just min / max <br>\n",
    "* ANGLE_INCREMENT - constant just min / max  <br>\n",
    "* NUMBER_RADIATION_ANGLES - min TO 1000 <br>\n",
    "* +- 20% HRRPUA <br>\n",
    "* +- 20% SOOT_YIELD=0.024 Table A.39 - SFPE page 3466 <br>\n",
    "* +- 20% radiative fraction PROPANE=0.3 Table 16.1 - FUG page 190 <br>\n",
    "* +- 10 TMPA Domain -  default =20 <br>\n",
    "* +- 0.8 - 0.99 EMISSIVITY Burner <br>\n",
    "* +- 0.8 - 0.99 EMISSIVITY Panel <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new min/max\n",
    "HRRPUA=333\n",
    "print(f'HRRPUA -20% = {round(HRRPUA*0.8,2)}')\n",
    "print(f'HRRPUA +20% = {round(HRRPUA*1.2,2)}')\n",
    "SY= 0.024 \n",
    "print(f'SY -20% = {round(SY*0.8,5)}')\n",
    "print(f'SY +20% = {round(SY*1.2,5)}')\n",
    "rf= 0.3 \n",
    "print(f'rf -20% = {round(rf*0.8,2)}')\n",
    "print(f'rf +20% = {round(rf*1.2,2)}')\n",
    "\n",
    "###\n",
    "#path_length max \n",
    "point1 = np.array([-0.15, -0.3, 1.2])\n",
    "point2 = np.array([0.15, 0.3, 1.2])\n",
    "\n",
    "#diagonal corner to corner of each panel \n",
    "distance = np.linalg.norm(point1 - point2)\n",
    "print(\"Distance between corner to the corner of the panels (diagonal) for max path_length:\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Informations for the script\n",
    "Propeties, Ranges and Sampling Method for the next step\n",
    "* params_info: **[(\"Name (here: FDS Command)\", min Value, max Value, \"sampling methods\")]**\n",
    "* sampling methods: \n",
    "    * 'simple' just switching randomly between min and max value\n",
    "    * 'LHS' using Latin Hypercube Sampling in the given range of min and max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMISSIVITY_Burner and EMISSIVITY_Panel are placeholder for unique labeling in the FDS Template \n",
    "params_info = [\n",
    "                ('PATH_LENGTH', 0.1, 1, 'simple'),\n",
    "                ('ANGLE_INCREMENT', 1, 5, 'simple'),\n",
    "                ('NUMBER_RADIATION_ANGLES', 100, 1000, 'LHS'),\n",
    "                ('HRRPUA', 266.4, 399.6, 'LHS'),\n",
    "                ('SOOT_YIELD', 0.0192, 0.0288, 'LHS'),\n",
    "                ('RADIATIVE_FRACTION', 0.24, 0.36, 'LHS'),\n",
    "                ('TMPA', 10, 25, 'LHS'),\n",
    "                ('EMISSIVITY_Burner', 0.8, 0.99, 'LHS'),\n",
    "                ('EMISSIVITY_Panel', 0.8, 0.99, 'LHS')\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write data to CSV file similar to cone script \n",
    "def write_csv(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        for row in data:\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "# Function to create a directory for better handling\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "#####IMPORTANT ADJUSTMENTS OF CASES AND SAMPLES#######\n",
    "# Defining propeties\n",
    "n_dims = len(params_info) # for n parameters\n",
    "n_samples = 2 # for n sample sets in each cases\n",
    "cases = 2 # n cases (generations of the seed - with each case the seed value is new randomly implemented)\n",
    "\n",
    "# Defining the parameters, ranges, and sampling methods - PATH_LENGTH distance digonal max 0.67082\n",
    "params_info = params_info\n",
    "\n",
    "# Split names, ranges, and sampling methods\n",
    "params_names = np.array([info[0] for info in params_info])\n",
    "params_ranges = np.array([[info[1], info[2]] for info in params_info])\n",
    "sampling_methods = np.array([info[3] for info in params_info])\n",
    "\n",
    "# Defining the directory where the cases will be located\n",
    "fds_input_dir = 'P:/Shared/Studium/Masterthesis/ParallelPanelBurnerSetup/RunReports/Cases_Launch'\n",
    "\n",
    "# FDS template location\n",
    "fds_input_temp = f'{fds_input_dir[0:-13]}/Templates/fds_input_template.fds'\n",
    "# Defining the name of the FDS file\n",
    "fds_label = \"MaCFP_Burner_\"\n",
    "\n",
    "dfs = [] \n",
    "\n",
    "# Looping over n cases\n",
    "for i in range(cases):\n",
    "    # Generate a random range for the integer\n",
    "    start = random.randint(0, 10000)\n",
    "    stop = random.randint(start+1, 10000)\n",
    "\n",
    "    # Generate a random integer for the seed within the generated range\n",
    "    random_integer = random.randrange(start, stop)\n",
    "    \n",
    "    # Creating a directory for the current cases and name it \n",
    "    cases = os.path.join(fds_input_dir, f\"case{i}_{random_integer}\")\n",
    "    create_directory(cases)\n",
    "    \n",
    "    # Generating a sample using Latin Hypercube Sampling or simple min-max sampling (random pick)\n",
    "    samples = []\n",
    "    for (min_val, max_val), sampling_method in zip(params_ranges, sampling_methods):\n",
    "\n",
    "        if sampling_method == 'LHS':\n",
    "            sample = LatinHypercube(d=1, seed=random_integer).random(n_samples) * (max_val - min_val) + min_val\n",
    "        elif sampling_method == 'simple':\n",
    "            sample = np.random.choice([min_val, max_val], size=n_samples)\n",
    "\n",
    "        samples.append(sample)\n",
    "\n",
    "    sample = np.column_stack(samples).astype(float)\n",
    "    \n",
    "    # Convert the array to a DataFrame\n",
    "    df = pd.DataFrame(sample, columns=[p[0] for p in params_info])\n",
    "    dfs.append(df)  \n",
    "\n",
    "    # Save the parameter values to a CSV file \n",
    "    df.to_csv(f'{fds_input_dir}/../TableData/case{i}_param_values.csv', index=False)\n",
    "  \n",
    "    # Looping over each parameter set for n samples\n",
    "    for j, param_set in enumerate(sample):\n",
    "        # Creating a directory for the current sample within the cases directory\n",
    "        sample_dir = os.path.join(cases, f\"{fds_label[0:6]}CASE{i}_sample{j}\")\n",
    "        create_directory(sample_dir)\n",
    "               \n",
    "        ####FDS file\n",
    "        # Reading the contents of the initial FDS file\n",
    "        with open(os.path.join(fds_input_dir, fds_input_temp), 'r') as fds_input:\n",
    "            fds_input_content = fds_input.readlines()\n",
    "        \n",
    "        # Add the CHID with the current sample and cases to the &HEAD line\n",
    "        for idx, line in enumerate(fds_input_content):\n",
    "            if \"&HEAD\" in line:\n",
    "                fds_input_content[idx] = f'&HEAD CHID=\"{fds_label}CASE{i}_sample{j}\", {line[29:]}\\n'\n",
    "                break\n",
    "        \n",
    "        # Modifying the FDS file with the current parameter set\n",
    "        # using Placeholder to EMISSIVITY_Panel / EMISSIVITY_Burner for unique values\n",
    "        for k, (param, _, _, _) in enumerate(params_info):\n",
    "            for idx, line in enumerate(fds_input_content):\n",
    "                if \"EMISSIVITY_Panel\" in line:\n",
    "                    fds_input_content[idx] = f\"      EMISSIVITY = {param_set[k]}\\n\"\n",
    "                elif \"EMISSIVITY_Burner\" in line:\n",
    "                    fds_input_content[idx] = f\"      EMISSIVITY = {param_set[k]}\\n\"\n",
    "                elif param in line:\n",
    "                    fds_input_content[idx] = f\"      {param} = {param_set[k]}\\n\"\n",
    "                    break\n",
    "                    \n",
    "        ####pleiades file \n",
    "        #pleiades file location\n",
    "        pleiades_file = f'{fds_input_dir[0:-13]}/Templates/job_fds.pleiades'\n",
    "\n",
    "        # Open and read the pleiades file\n",
    "        with open(pleiades_file, 'r') as input_file:\n",
    "            file_content = input_file.read()\n",
    "\n",
    "        # Replace '******' with the appropriate label\n",
    "        new_content = file_content.replace('******', f'{fds_label}CASE{i}_sample{j}')\n",
    "        \n",
    "        fds_input_label_gen_sample = f\"{fds_label}CASE{i}_sample{j}.fds\"\n",
    "        fds_input_filepath = os.path.join(sample_dir, fds_input_label_gen_sample)\n",
    "        \n",
    "        # Save the result with Unix line endings\n",
    "        out_file_path = f'{sample_dir}/job_fds.pleiades'\n",
    "        with io.open(out_file_path, 'w', newline='\\n') as output_file:\n",
    "            output_file.write(new_content)\n",
    "        \n",
    "        # Saving the modified FDS file in the folder of the sample \n",
    "        with open(fds_input_filepath, 'w') as new_fds_file:\n",
    "            new_fds_file.writelines(fds_input_content)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "param_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'{fds_input_dir}/../TableData/case0_param_values.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
