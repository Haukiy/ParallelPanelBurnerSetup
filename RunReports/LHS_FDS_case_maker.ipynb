{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pylab\n",
    "import string\n",
    "import fdsreader\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import spotpy\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "from pyDOE import lhs\n",
    "import random\n",
    "import shutil\n",
    "import io\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LatinHypercube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latin Hypercube Sampling (LHS) is a statistical method used for generating a representative sample of parameter values from a multi-dimensional parameter space. The method involves dividing each dimension of the parameter space into equally-sized intervals and selecting one random point from each interval, such that each point is chosen exactly once. The resulting sample is thus representative of the parameter space in a more even and efficient way than a completely random sampling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the LHS sample using `LatinHypercube` from `scipy.stats.qmc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "\n",
    "# Define the number of dimensions and the number of samples to generate\n",
    "n_dims = 2\n",
    "n_samples = 10\n",
    "\n",
    "# Define the parameter ranges for each dimension\n",
    "params_ranges = np.array([[0, 1], [0, 1]])\n",
    "\n",
    "# Generate a Latin Hypercube sample within the parameter ranges\n",
    "sample = LatinHypercube(d=n_dims, seed=123).random(n_samples) * (params_ranges[:, 1] - params_ranges[:, 0]) + params_ranges[:, 0]\n",
    "\n",
    "# Create a grid to show the parameter space\n",
    "xx, yy = np.meshgrid(np.linspace(params_ranges[0, 0], params_ranges[0, 1], 10),\n",
    "                     np.linspace(params_ranges[1, 0], params_ranges[1, 1], 10))\n",
    "grid = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Plot the resulting sample and the parameter space grid\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "axs[0].scatter(sample[:, 0], sample[:, 1])\n",
    "axs[0].set_xlabel('Parameter 1')\n",
    "axs[0].set_ylabel('Parameter 2')\n",
    "axs[0].set_title('Latin Hypercube Sample')\n",
    "\n",
    "axs[1].scatter(grid[:, 0], grid[:, 1], color='gray')\n",
    "axs[1].scatter(sample[:, 0], sample[:, 1])\n",
    "axs[1].set_xlabel('Parameter 1')\n",
    "axs[1].set_ylabel('Parameter 2')\n",
    "axs[1].set_title('Parameter Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latin Hypercube Sampling is designed to spread the sample points evenly throughout the parameter space, while still maintaining randomness. In other words, the LHS algorithm aims to fill the parameter space with points in such a way that each point is representative of a different region of the space, while avoiding clusters or gaps of points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameter settings:\n",
    "\n",
    "* PATH_LENGTH - constant just min / max <br>\n",
    "* ANGLE_INCREMENT - constant just min / max  <br>\n",
    "* NUMBER_RADIATION_ANGLES - min TO 1000 <br>\n",
    "* +- 20% HRRPUA <br>\n",
    "* +- 20% SOOT_YIELD=0.024 Table A.39 - SFPE page 3466 <br>\n",
    "* +- 20% radiative fraction PROPANE=0.3 Table 16.1 - FUG page 190 <br>\n",
    "* +- 10 TMPA Domain -  default =20 <br>\n",
    "* +- 0.8 - 0.99 EMISSIVITY Burner <br>\n",
    "* +- 0.8 - 0.99 EMISSIVITY Panel <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new min/max\n",
    "HRRPUA=333\n",
    "print(f'HRRPUA -20% = {round(HRRPUA*0.8,2)}')\n",
    "print(f'HRRPUA +20% = {round(HRRPUA*1.2,2)}')\n",
    "SY= 0.024 \n",
    "print(f'SY -20% = {round(SY*0.8,5)}')\n",
    "print(f'SY +20% = {round(SY*1.2,5)}')\n",
    "rf= 0.3 \n",
    "print(f'rf -20% = {round(rf*0.8,2)}')\n",
    "print(f'rf +20% = {round(rf*1.2,2)}')\n",
    "\n",
    "###\n",
    "#path_length max \n",
    "point1 = np.array([-0.15, -0.3, 1.2])\n",
    "point2 = np.array([0.15, 0.3, 1.2])\n",
    "\n",
    "#diagonal corner to corner of each panel \n",
    "distance = np.linalg.norm(point1 - point2)\n",
    "print(\"Distance between corner to the corner of the panels (diagonal) for max path_length:\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Informations for the script\n",
    "Propeties, Ranges and Sampling Method for the next step\n",
    "* params_info: **[('Name', min Value, max Value, 'sampling methods', seed)]**\n",
    "    * 'Name' = for FDS use cases the FDS Command\n",
    "    * 'min Value', 'max Value' = Range \n",
    "    * sampling methods: \n",
    "        * 'simple' just switching randomly between min and max value\n",
    "        * 'LHS' using Latin Hypercube Sampling in the given range of min and max value\n",
    "    * seed:\n",
    "        * 'None' using random number = constant for each case session (for reproduction) \n",
    "        * 'user defined' value e.g. 123 (if range is for two parameters equal) \n",
    "        * 'random' new random besides the default random preset     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Range Info:\n",
    "\n",
    "* LHC_Session_2023-04-06_48\n",
    "```python\n",
    "> params_info = [\n",
    "                ('PATH_LENGTH', 0.1, 1, 'simple',None),\n",
    "                ('ANGLE_INCREMENT', 1, 5, 'simple',None),\n",
    "                ('NUMBER_RADIATION_ANGLES', 100, 1000, 'LHS',None),\n",
    "                ('HRRPUA', 266.4, 399.6, 'LHS',None),\n",
    "                ('SOOT_YIELD', 0.0192, 0.0288, 'LHS',None),\n",
    "                ('RADIATIVE_FRACTION', 0.24, 0.36, 'LHS',None),\n",
    "                ('TMPA', 10, 25, 'LHS',None),\n",
    "                ('EMISSIVITY_Burner', 0.8, 0.99, 'LHS','random'),\n",
    "                ('EMISSIVITY_Panel', 0.8, 0.99, 'LHS','random')\n",
    "              ]\n",
    "```\n",
    "* LHC_Session_2023-04-11_79\n",
    "```python\n",
    "> params_info = [\n",
    "                ('PATH_LENGTH', 0.1, 1, 'simple',None),\n",
    "                ('ANGLE_INCREMENT', 1, 1.1, 'simple',None),\n",
    "                ('NUMBER_RADIATION_ANGLES', 298.42201244958414, 480.04742664501515, 'LHS',None),\n",
    "                ('HRRPUA', 270.606457842538, 347.8070191434622, 'LHS',None),\n",
    "                ('SOOT_YIELD',0.01950316813279548, 0.025067172550880132, 'LHS',None),\n",
    "                ('RADIATIVE_FRACTION',  0.2437896016599445, 0.313339656886002, 'LHS',None),\n",
    "                ('TMPA', 13.563698346385443, 17.167457110750256, 'LHS',None),\n",
    "                ('EMISSIVITY_Burner', 0.8096408887880744, 0.99, 'LHS','random'),\n",
    "                ('EMISSIVITY_Panel',0.8294436327809379, 0.99, 'LHS','random')\n",
    "              ]\n",
    "```\n",
    "* LHC_Session_2023-04-12_67\n",
    "```python\n",
    "> params_info = [\n",
    "                ('PATH_LENGTH', 0.1, 0.11000000000000001, 'simple',None),\n",
    "                ('ANGLE_INCREMENT', 1, 1.1, 'simple',None),\n",
    "                ('NUMBER_RADIATION_ANGLES', 320.4369993135468, 480.04742664501515, 'LHS',None),\n",
    "                ('HRRPUA', 270.606457842538, 324.60743789146363, 'LHS',None),\n",
    "                ('SOOT_YIELD',0.01950316813279548, 0.023395130658844118, 'LHS',None),\n",
    "                ('RADIATIVE_FRACTION', 0.2437896016599445,0.313339656886002, 'LHS',None),\n",
    "                ('TMPA',13.563698346385443, 17.167457110750256, 'LHS',None),\n",
    "                ('EMISSIVITY_Burner',  0.8096408887880744, 0.99, 'LHS','random'),\n",
    "                ('EMISSIVITY_Panel', 0.8294436327809379, 0.9394230582691327, 'LHS','random')\n",
    "              ]\n",
    "```\n",
    "* LHC_Session_2023-04-12_99\n",
    "```python\n",
    "> params_info = [\n",
    "                ('PATH_LENGTH', 0.1089, 0.11000000000000001, 'simple', None),\n",
    "                ('ANGLE_INCREMENT', 1.0, 1.1, 'simple', None),\n",
    "                ('NUMBER_RADIATION_ANGLES', 424.34760585618665, 467.35705900811786, 'LHS', None),\n",
    "                ('HRRPUA', 304.1405926518197, 321.93583746395694, 'LHS', None),\n",
    "                ('SOOT_YIELD', 0.021920042713644505, 0.02320258288028506, 'LHS', None),\n",
    "                ('RADIATIVE_FRACTION', 0.2880269301769507, 0.30885143975037804, 'LHS', None),\n",
    "                ('TMPA', 15.846553324501757, 16.94421528535939, 'LHS', None),\n",
    "                ('EMISSIVITY_Burner', 0.901509323773234, 0.9470999704528581, 'LHS', 'random'),\n",
    "                ('EMISSIVITY_Panel', 0.8590603805739137, 0.8950460897516035, 'LHS', 'random'),\n",
    "              ]\n",
    "```\n",
    "NEW TRY\n",
    "* LHC_Session_2023-04-13_94\n",
    "```python\n",
    "> params_info = [\n",
    "              ('PATH_LENGTH', 0.1, 1, 'simple',None),\n",
    "              ('ANGLE_INCREMENT', 1, 5, 'simple',None),\n",
    "              ('NUMBER_RADIATION_ANGLES', 100, 1000, 'LHS',None),\n",
    "              ('HRRPUA', 300, 600, 'LHS',None),\n",
    "              ('SOOT_YIELD', 0.015, 0.03, 'LHS',None),\n",
    "              ('RADIATIVE_FRACTION', 0.20, 0.40, 'LHS',None),\n",
    "              ('TMPA', 10, 30, 'LHS',None),\n",
    "              ('EMISSIVITY_Burner', 0.8, 0.99, 'LHS','random'),\n",
    "              ('EMISSIVITY_Panel', 0.8, 0.99, 'LHS','random')\n",
    "            ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EMISSIVITY_Burner and EMISSIVITY_Panel are placeholder for unique labeling in the FDS Template \n",
    "params_info = [\n",
    "              ('PATH_LENGTH', 0.1, 1, 'simple',None),\n",
    "              ('ANGLE_INCREMENT', 1, 5, 'simple',None),\n",
    "              ('NUMBER_RADIATION_ANGLES', 100, 1000, 'LHS',None),\n",
    "              ('HRRPUA', 300, 600, 'LHS',None),\n",
    "              ('SOOT_YIELD', 0.015, 0.03, 'LHS',None),\n",
    "              ('RADIATIVE_FRACTION', 0.20, 0.40, 'LHS',None),\n",
    "              ('TMPA', 10, 30, 'LHS',None),\n",
    "              ('EMISSIVITY_Burner', 0.8, 0.99, 'LHS','random'),\n",
    "              ('EMISSIVITY_Panel', 0.8, 0.99, 'LHS','random')\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write data to CSV file similar to cone script \n",
    "def write_csv(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        for row in data:\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "# Function to create a directory for better handling\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "#####IMPORTANT ADJUSTMENTS OF CASES AND SAMPLES#######\n",
    "# Defining propeties\n",
    "n_samples = 40 # for n sample sets in each cases\n",
    "cases = 5 # n cases (generations of the seed - with each case the seed value is new randomly implemented)\n",
    "\n",
    "# Defining the parameters, ranges, and sampling methods - PATH_LENGTH distance digonal max 0.67082\n",
    "params_info = params_info\n",
    "\n",
    "# Split names, ranges, sampling methods, and seeds\n",
    "params_names = np.array([info[0] for info in params_info])\n",
    "params_ranges = np.array([[info[1], info[2]] for info in params_info])\n",
    "sampling_methods = np.array([info[3] for info in params_info])\n",
    "seeds = np.array([info[4] for info in params_info])\n",
    "\n",
    "#unique id\n",
    "un_id=random.randint(0, 100)\n",
    "\n",
    "# Get the current day\n",
    "current_day = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Defining the directory where the cases will be located, Naming: Current day of the Case Generation plus unique id, e.g. LHC_Session_2023-04-11_79 --> 79 = id\n",
    "fds_input_dir = f'../BurnerSims/LHC_Session_{current_day}_{un_id}'\n",
    "# FDS template location\n",
    "fds_input_temp = f'Templates/fds_input_template.fds'\n",
    "# Defining the name of the FDS file\n",
    "fds_label = \"MaCFP_Burner_\"\n",
    "\n",
    "dfs = [] \n",
    "\n",
    "# Looping over n cases\n",
    "for i in range(cases):\n",
    "    # Generate a random range for the integer\n",
    "    start = random.randint(0, 10000)\n",
    "    stop = random.randint(start+1, 10000)\n",
    "\n",
    "    # Generate a random integer for the seed within the generated range\n",
    "    random_integer = random.randrange(start, stop)\n",
    "    \n",
    "    # Creating a directory for the current cases and name it \n",
    "    cases = os.path.join(fds_input_dir, f\"case{i}\")\n",
    "    create_directory(cases)\n",
    "    \n",
    "    # Generating a sample using Latin Hypercube Sampling or simple min-max sampling (random pick)\n",
    "    samples = []\n",
    "    seeds_used = []  # Add a list to store the seeds used and their associated parameter names, maybe seeds are needed for reproduction \n",
    "    \n",
    "    for param, (min_val, max_val), sampling_method, seed in zip(params_names, params_ranges, sampling_methods, seeds):\n",
    "\n",
    "            # parameter-specific seed: 'None' random_integer = constant for the case session (for reproduction), 'user defined' = any value, \"random\" = new random seed \n",
    "            if seed is None:\n",
    "                seed_to_use = random_integer\n",
    "            elif seed == 'random':\n",
    "                seed_to_use = random.randint(0, 10000)\n",
    "            else:\n",
    "                seed_to_use = seed\n",
    "\n",
    "            seeds_used.append((param, seed_to_use))  # Store the parameter name and seed used\n",
    "\n",
    "            ##### (max_val - min_val) + min_val --> scales the samples from the uniform distribution to the range specified by min_val and max_val\n",
    "            if sampling_method == 'LHS':\n",
    "                sample = LatinHypercube(d=1, seed=seed_to_use).random(n_samples) * (max_val - min_val) + min_val\n",
    "            elif sampling_method == 'simple':\n",
    "                # https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "                sample = np.random.choice([min_val, max_val], size=n_samples)\n",
    "\n",
    "            samples.append(sample)\n",
    "\n",
    "    sample = np.column_stack(samples).astype(float)  \n",
    "    \n",
    "    # Convert the array to a DataFrame\n",
    "    df = pd.DataFrame(sample, columns=[p[0] for p in params_info])\n",
    "    dfs.append(df)  \n",
    "\n",
    "    # Save the parameter values to a CSV file \n",
    "    df.to_csv(f'{fds_input_dir}/../../RunReports/TableData/LHC_Session_{current_day}_{un_id}_case{i}_param_values.csv', index=False)\n",
    "  \n",
    "    # Looping over each parameter set for n samples\n",
    "    for j, param_set in enumerate(sample):\n",
    "        # Creating a directory for the current sample within the cases directory\n",
    "        sample_dir = os.path.join(cases, f\"{fds_label[0:6]}CASE{i}_sample{j}\")\n",
    "        create_directory(sample_dir)\n",
    "               \n",
    "        ####FDS file######\n",
    "        # Reading the contents of the initial FDS file\n",
    "        with open(fds_input_temp, 'r') as fds_input:\n",
    "            fds_input_content = fds_input.readlines()      \n",
    "        \n",
    "        # Modifying the FDS file with the current parameter set\n",
    "        # using Placeholder to EMISSIVITY_Panel / EMISSIVITY_Burner for unique values\n",
    "        for k, (param, _, _, _, _) in enumerate(params_info):\n",
    "            for idx, line in enumerate(fds_input_content):\n",
    "                if \"EMISSIVITY_Panel\" in line:\n",
    "                    fds_input_content[idx] = f\"      EMISSIVITY = {param_set[k]}\\n\"\n",
    "                elif \"EMISSIVITY_Burner\" in line:\n",
    "                    fds_input_content[idx] = f\"      EMISSIVITY = {param_set[k]}\\n\"\n",
    "                elif param in line:\n",
    "                    fds_input_content[idx] = f\"      {param} = {param_set[k]}\\n\"\n",
    "                    break\n",
    "                    \n",
    "        seeds_str = \", \".join(f\"{param}({seed})\" for param, seed in seeds_used)  # Convert the list of seeds and parameter names to a comma-separated string           \n",
    "        # Add the CHID with the current sample, cases, and Seeds of the LHC to the &HEAD line\n",
    "        for idx, line in enumerate(fds_input_content):\n",
    "            if \"&HEAD\" in line:\n",
    "                fds_input_content[idx] = f'&HEAD CHID=\"{fds_label}CASE{i}_sample{j}\",  TITLE=\"Parallel Panel Test, PMMA, Propane, 60 kW,Seeds= {seeds_str}\"/ \\n'\n",
    "                break    \n",
    "                \n",
    "        ####pleiades file###### \n",
    "        #pleiades file location\n",
    "        pleiades_file = f'Templates/job_fds.pleiades'\n",
    "\n",
    "        # Open and read the pleiades file\n",
    "        with open(pleiades_file, 'r') as input_file:\n",
    "            file_content = input_file.read()\n",
    "\n",
    "        # Replace '******' with the appropriate label\n",
    "        new_content = file_content.replace('******', f'{fds_label}CASE{i}_sample{j}')\n",
    "        \n",
    "        fds_input_label_gen_sample = f\"{fds_label}CASE{i}_sample{j}.fds\"\n",
    "        fds_input_filepath = os.path.join(sample_dir, fds_input_label_gen_sample)\n",
    "        \n",
    "        # Save the result with Unix line endings\n",
    "        out_file_path = f'{sample_dir}/job_fds.pleiades'\n",
    "        with io.open(out_file_path, 'w', newline='\\n') as output_file:\n",
    "            output_file.write(new_content)\n",
    "        \n",
    "        # Saving the modified FDS file in the folder of the sample \n",
    "        with open(fds_input_filepath, 'w') as new_fds_file:\n",
    "            new_fds_file.writelines(fds_input_content)\n",
    "\n",
    "# Copy the launch_job_subdir.sh to the fds_input_dir for easy access\n",
    "shutil.copy('Templates/launch_job_subdir.sh', fds_input_dir)\n",
    "\n",
    "###store input parameter ranges in .txt\n",
    "with open(f'{fds_input_dir}/param_set_ranges_{current_day}_{un_id}.txt', 'w') as file:\n",
    "    # Write the header\n",
    "    file.write(\"Parameter and their ranges:\\n\")\n",
    "\n",
    "    # Iterate through the params_info_list and write each item to the file\n",
    "    for best_value_info in params_info:\n",
    "        file.write(f\"{best_value_info[0]}: {best_value_info[1]}, {best_value_info[2]},{best_value_info[3]},{best_value_info[4]}\\n\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "param_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(\"DONE!\")\n",
    "print(f'Path of the created FDS files: {fds_input_dir[3:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files that end with \"param_values.csv\" in the specified directory\n",
    "templates=f\"{fds_input_dir}/../../RunReports/TableData\"\n",
    "csv_files = [file for file in os.listdir(templates) if file.startswith(f\"LHC_Session_{current_day}\") and file.endswith(f\"param_values.csv\")]\n",
    "\n",
    "# Print the list of CSV files\n",
    "for csv_file in csv_files: \n",
    "    print(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1 #CaseId\n",
    "pd.read_csv(f'{templates}/LHC_Session_{current_day}_{un_id}_case{i}_param_values.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
