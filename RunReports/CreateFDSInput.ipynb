{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Tools to Generate FDS Input Lines\n",
    "\n",
    "For example multiple `DEVC` lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pylab\n",
    "import string\n",
    "import fdsreader\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import Processing as proc\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# Reload Python modules for changes that occured during runtime.\n",
    "# reload(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Package Versions')\n",
    "print('----------------')\n",
    "print('Pandas version: {}'.format(pd.__version__))\n",
    "print('Numpy version: {}'.format(np.__version__))\n",
    "print('fdsreader version: {}'.format(fdsreader.__version__))\n",
    "print('Matplotlib version: {}'.format(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get letters for automatic labeling.\n",
    "letters = list(string.ascii_uppercase)\n",
    "print(string.ascii_uppercase)\n",
    "\n",
    "\n",
    "# Path to experiment data.\n",
    "exp_root = os.path.join(\"..\", \"GeneralInformation\", \"macfp-db\")\n",
    "exp_macfp_dir = os.path.join(exp_root, \"Fire_Growth\", \n",
    "                             \"NIST_Parallel_Panel\", \"Experimental_Data\")\n",
    "\n",
    "\n",
    "# Directory used to collect the output produced by this notebook.\n",
    "output_dir = \"CreateFDSInputOutput\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    print(\"* Output directory created.\")\n",
    "else:\n",
    "    print(\"* Output directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get commit hash of MaCFP repo.\n",
    "# ------------------------------------\n",
    "# Commit/revision used here:\n",
    "# MaCFP HEAD, revision (short): b8b0c1b\n",
    "# MaCFP HEAD, revision  (long): b8b0c1b048f1a1901f2e012463f2a7c168eb486a\n",
    "# MaCFP description: macfp-1.0-639-gb8b0c1b\n",
    "# ------------------------------------\n",
    "\n",
    "# Check where you are at.\n",
    "# Short form of commit hash.\n",
    "# (git rev-parse --short HEAD)\n",
    "revision_s = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], \n",
    "                                     cwd=exp_root).strip().decode()\n",
    "\n",
    "# Long form of commit hash.\n",
    "# (git rev-parse HEAD)\n",
    "revision_l = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], \n",
    "                                     cwd=exp_root).strip().decode()\n",
    "\n",
    "# Tag (version) and commit number.\n",
    "# Needs tags.\n",
    "description = subprocess.check_output([\"git\", \"describe\"], \n",
    "                                     cwd=exp_root).strip().decode()\n",
    "\n",
    "\n",
    "# Show actuals.\n",
    "print(\"MaCFP git repo version\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"MaCFP HEAD, revision (short): {revision_s}\")\n",
    "print(f\"MaCFP HEAD, revision  (long): {revision_l}\")\n",
    "print(f\"MaCFP description: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names.\n",
    "os.listdir(exp_macfp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read centre line heat flux to empty panel.\n",
    "centreline_hf_path = os.path.join(exp_macfp_dir, \"Burner_HF_Centerline_multi-layer.csv\")\n",
    "centreline_hf_df = pd.read_csv(centreline_hf_path, header=0, skiprows=[1])\n",
    "\n",
    "\n",
    "# Check result.\n",
    "centreline_hf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burner RAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-values for time steps. Copy over manually.\n",
    "hrr_target = 60  # kW\n",
    "\n",
    "# Initialise RAMP points.\n",
    "burner_ramp_points = [[0,0, 0]]\n",
    "\n",
    "for hrr_id, hrr in enumerate(centreline_hf_df.HRR):\n",
    "    n_hrr = hrr / hrr_target\n",
    "    n_time = centreline_hf_df.Time[hrr_id]\n",
    "    \n",
    "    burner_ramp_points.append([n_time, n_hrr, hrr])\n",
    "    \n",
    "\n",
    "burner_ramp_nucleus = \"&RAMP ID='BurnerRamp', T={: >3}, F={} /\"\n",
    "for burner_ramp_point in burner_ramp_points:\n",
    "    n_ramp = burner_ramp_nucleus.format(burner_ramp_point[0], \n",
    "                                        burner_ramp_point[1])\n",
    "    print(n_ramp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result.\n",
    "plt.plot(np.array(burner_ramp_points)[:,0],\n",
    "         np.array(burner_ramp_points)[:,2],\n",
    "         marker='o')\n",
    "    \n",
    "    \n",
    "# Plot meta data.\n",
    "plt.xlabel(\"Time / s\")\n",
    "plt.ylabel(\"Energy Release Rate / kW\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conductivity and Specific Heat RAMPs, Kaowool Blanket\n",
    "\n",
    "Data is mixed from multiple sources. `MATL` and `SURF` are based on the FDS validation case [\"NIST_NRC_Parallel_Panels\"](https://github.com/firemodels/fds/blob/master/Validation/NIST_NRC_Parallel_Panels/FDS_Input_Files/PMMA_60_kW.fds). Thus, all parameters that are unknown are using the values of said case as default. For example the pea-gravel and the sand use the same `MATL`. Same is true for the Marinite and plywood boards.\n",
    "\n",
    "#### Conductivity RAMP\n",
    "Data from [MaCFP](https://github.com/MaCFP/matl-db/tree/master/PMMA/Validation_Data/NIST_Gasification_Apparatus) for high temperature. Data from [DBI/Lund](https://github.com/MaCFP/matl-db/tree/master/PMMA/Calibration_Data/DBI_Lund) for low temperature and density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaCFP: Morgan Thermal Ceramics Kaowool PM Insulation Board\n",
    "macfp_kaowool = {\n",
    "    \"Density\": 256, \n",
    "    \"Heat Capacity\": {\n",
    "        \"Temperatures\": [980],\n",
    "        \"Values\": [1.070]},\n",
    "    \"Conductivity\":{\n",
    "        \"Temperatures\": [260.0, 538.0, 816.0, 1093.0], \n",
    "        \"Values\": [0.0576, 0.085, 0.125, 0.183]}\n",
    "}\n",
    "\n",
    "# DBI/Lund: Morgan Thermal Ceramics Super wool plus\n",
    "dbi_superwool = {\n",
    "    \"Density\": 64, \n",
    "    \"Heat Capacity\": {\n",
    "        \"Temperatures\": None,\n",
    "        \"Values\": None},\n",
    "    \"Conductivity\":{\n",
    "        \"Temperatures\": [25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.5, 60.0, 65.0, 70.0], \n",
    "        \"Values\": [0.03364, 0.03437, 0.03520, 0.03618, 0.03721, 0.03795, 0.03854, 0.03920, 0.04003, 0.04088]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise RAMP points.\n",
    "cond_ramp_points = list()\n",
    "\n",
    "# Collect data points for low temperature.\n",
    "cond_data  = dbi_superwool[\"Conductivity\"]\n",
    "for temp_id, temp in enumerate(cond_data[\"Temperatures\"]):\n",
    "    val = cond_data[\"Values\"][temp_id]\n",
    "    cond_ramp_points.append([temp, val])\n",
    "\n",
    "# Collect data points for heigh temperature.\n",
    "cond_data  = macfp_kaowool[\"Conductivity\"]\n",
    "for temp_id, temp in enumerate(cond_data[\"Temperatures\"]):\n",
    "    val = cond_data[\"Values\"][temp_id]\n",
    "    cond_ramp_points.append([temp, val])\n",
    "    \n",
    "    \n",
    "# Show result.\n",
    "# cond_ramp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAMP input.\n",
    "ramp_lines = list()\n",
    "ramp_nucleus = \"&RAMP ID='COND_KAOWOOL_BLANKET', T={: >6}, F={} /\"\n",
    "\n",
    "for data_point in cond_ramp_points:\n",
    "    ramp_line = ramp_nucleus.format(data_point[0],\n",
    "                                    data_point[1])\n",
    "    print(ramp_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result.\n",
    "plt.plot(np.array(cond_ramp_points)[:,0],\n",
    "         np.array(cond_ramp_points)[:,1],\n",
    "         marker='o')\n",
    "    \n",
    "    \n",
    "# Plot meta data.\n",
    "plt.xlabel(\"Temperature / °C\")\n",
    "plt.ylabel(\"Thermal Conductivity / W/(m * K)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conductivity and Specific Heat RAMPs of the Panels\n",
    "\n",
    "Data is mixed from multiple sources. `MATL` and `SURF` are based on the FDS validation case [\"NIST_NRC_Parallel_Panels\"](https://github.com/firemodels/fds/blob/master/Validation/NIST_NRC_Parallel_Panels/FDS_Input_Files/PMMA_60_kW.fds). Thus, all parameters that are unknown are using the values of said case as default. For example the Marinite and plywood boards use the same `MATL`.\n",
    "\n",
    "#### Conductivity RAMP\n",
    "Data from [MaCFP](https://github.com/MaCFP/macfp-db/tree/master/Fire_Growth/NIST_Parallel_Panel/Documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Length (RADI)\n",
    "\n",
    "User guide:\n",
    "\n",
    "For a given gas temperature and species composition, RadCal computes a single effective absorption coefficient\n",
    "that is independent of wavelength. To calculate this coefficient, a user-specified `PATH_LENGTH` (m)\n",
    "is needed. Its default value is 0.1 m. The choice of `PATH_LENGTH` can be based on the physical size of\n",
    "the fire, the compartment, or the overall computational domain, depending on the application. The default\n",
    "value has been chosen to capture accurately radiation heat transfer in and around the fire itself. A useful\n",
    "“rule of thumb” for this length scale is 4V=A, where V is the volume of the region of interest and A is the\n",
    "encompassing surface area. This region might be the volume occupied by the fire itself or a flashed-over compartment. Alternatively, if the application involves calculating the heat flux to distant targets, a more\n",
    "appropriate `PATH_LENGTH` might be the distance from the fire to the target. A sensitivity analysis should be\n",
    "done in any case to determine how the chosen `PATH_LENGTH` affects the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible value for PATH_LENGTH.\n",
    "domain_x = 0.8\n",
    "domain_y = 1.2\n",
    "domain_z = 3.2\n",
    "\n",
    "domain_vol = domain_x * domain_y * domain_z\n",
    "\n",
    "domain_surf = (domain_x * domain_y + \\\n",
    "               domain_x * domain_z + \\\n",
    "               domain_z * domain_y) * 2\n",
    "\n",
    "path_length = 4 * domain_vol / domain_surf\n",
    "path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEVC Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device values.\n",
    "\n",
    "# &DEVC ID='hf', XYZ=..., IOR=-2, QUANTITY='GAUGE HEAT FLUX', PROP_ID='hfp' /\n",
    "# &PROP ID='hfp', GAUGE_TEMPERATURE=80., GAUGE_EMISSIVITY=0.9 /\n",
    "\n",
    "# Defaults.\n",
    "gauge_temperaturs = np.array([\n",
    "    [20.0, 20.0, 20.0, 20.0, 20.0],\n",
    "    [20.0, 20.0, 20.0, 20.0, 20.0],\n",
    "    [20.0, 20.0, 20.0, 20.0, 20.0],\n",
    "    [20.0, 20.0, 20.0, 20.0, 20.0]\n",
    "])\n",
    "\n",
    "gauge_emissivities = np.array([\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positions.\n",
    "hf_gauge_locations = {\n",
    "    \"PanelFace\": 15,\n",
    "    \"Heights\": [20,50,75,100],\n",
    "    \"Horizontal\": [-25,-15,0,15,25]}\n",
    "\n",
    "\n",
    "comment_nucleus = \"# Height: {} cm\"\n",
    "devc_nucleus = \"\\\n",
    "&DEVC ID       = 'HF_y{}_z{}',\\n\\\n",
    "      IOR      = -1,\\n\\\n",
    "      XYZ      = {}, {}, {},\\n\\\n",
    "      QUANTITY = 'GAUGE HEAT FLUX' /\\n\"\n",
    "\n",
    "\n",
    "\n",
    "panelface = hf_gauge_locations[\"PanelFace\"]\n",
    "for height in hf_gauge_locations[\"Heights\"]:\n",
    "    print(comment_nucleus.format(height))\n",
    "    \n",
    "    for horizontal in hf_gauge_locations[\"Horizontal\"]:\n",
    "        x_pos = panelface/100\n",
    "        y_pos = horizontal/100\n",
    "        z_pos = height/100\n",
    "        n_devc = devc_nucleus.format(horizontal,height,x_pos,y_pos,z_pos)\n",
    "        \n",
    "        print(n_devc)\n",
    "    print('')  # Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
